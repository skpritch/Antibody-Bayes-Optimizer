{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, pandas as pd, uuid, pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig\n",
    "# 1. Load model\n",
    "\n",
    "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model   = ESMC.from_pretrained(\"esmc_300m\").to(device).eval()\n",
    "config  = LogitsConfig(return_embeddings=True)   # <-- fixed\n",
    "print(\"ESM-C ready\")\n",
    "# 2. Helper: return mean-pooled (960-D) AND full tensor (L×960)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def embed_seq(seq: str):\n",
    "    prot   = ESMProtein(sequence=seq)\n",
    "    toks   = model.encode(prot).to(device)\n",
    "    out    = model.logits(toks, config)          # residue embeddings present\n",
    "    full   = np.asarray(out.embeddings, dtype=np.float32)  # (L,960)\n",
    "    pooled = torch.from_numpy(full).to(device).mean(dim=0)\n",
    "    return pooled.cpu().numpy(), full            # (960,), (L,960)\n",
    "# 3. Read + normalise + pad sequences\n",
    "INPUT_JSON  = \"../data/raw/cd98_test.json\"\n",
    "SEQ_COL     = \"sequence\"\n",
    "\n",
    "df = pd.read_json(INPUT_JSON)\n",
    "\n",
    "def normalise(x):\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return \"\".join(x)\n",
    "    if isinstance(x, dict) and \"sequence\" in x:\n",
    "        return str(x[\"sequence\"])\n",
    "    return str(x)\n",
    "\n",
    "df[SEQ_COL] = df[SEQ_COL].apply(normalise)\n",
    "\n",
    "max_len = df[SEQ_COL].str.len().max()\n",
    "PAD_CHAR = \"X\"\n",
    "df[SEQ_COL] = df[SEQ_COL].apply(lambda s: s.ljust(max_len, PAD_CHAR))\n",
    "print(f\"All sequences padded to length {max_len}\")\n",
    "# 4. Embed every sequence ➜ collect pooled + tensor + flattened\n",
    "SAVE_DIR = Path(\"../data/processed/full_tensors\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pooled_vecs, tensor_paths, flat_vecs = [], [], []\n",
    "\n",
    "for seq in tqdm(df[SEQ_COL], desc=\"Embedding\"):\n",
    "    pooled, tensor = embed_seq(seq)\n",
    "\n",
    "    # save full tensor\n",
    "    fname = SAVE_DIR / f\"{uuid.uuid4().hex}.npy\"\n",
    "    np.save(fname, tensor)\n",
    "\n",
    "    pooled_vecs.append(pooled)\n",
    "    tensor_paths.append(str(fname))\n",
    "    flat_vecs.append(tensor.flatten())        # for PCA\n",
    "\n",
    "# 5. Fit Incremental PCA → 1 024 D and transform\n",
    "batch_size = 16\n",
    "n_components = 16\n",
    "pca = IncrementalPCA(n_components=n_components, batch_size=batch_size)\n",
    "for i in range(0, len(flat_vecs), batch_size):\n",
    "    pca.partial_fit(np.stack(flat_vecs[i:i+batch_size]))\n",
    "\n",
    "pca_vecs = pca.transform(np.stack(flat_vecs))  # (N,1024)\n",
    "\n",
    "# persist PCA model\n",
    "with open(f\"../data/processed/pca_{n_components}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pca, f)\n",
    "print(f\"Saved PCA model to ../data/processed/pca_{n_components}.pkl\")\n",
    "\n",
    "# 6. Assemble augmented DataFrame and save to JSON\n",
    "df[\"embedding_mean\"]     = [v.tolist() for v in pooled_vecs]\n",
    "df[f\"embedding_pca{n_components}\"]  = [v.tolist() for v in pca_vecs]\n",
    "df[\"tensor_path\"]        = tensor_paths\n",
    "\n",
    "OUTPUT_JSON = \"../data/processed/cd98_test_embeds.json\"\n",
    "df.to_json(OUTPUT_JSON, orient=\"records\", force_ascii=False)\n",
    "print(\"✓ wrote\", OUTPUT_JSON)\n",
    "\n",
    "# Quick spot-check\n",
    "sample = df.iloc[0]\n",
    "print(\"Mean-pooled len:\", len(sample[\"embedding_mean\"]),\n",
    "      \"| PCA len:\", len(sample[f\"embedding_pca{n_components}\"]),\n",
    "      \"| tensor_path:\", sample[\"tensor_path\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
