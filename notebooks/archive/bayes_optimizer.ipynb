{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c0ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import numpy as np, pandas as pd, torch, gpytorch, json, random, math\n",
    "from pathlib import Path\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "from os import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from esm.models.esmc import ESMC\n",
    "from esm.sdk.api import ESMProtein, LogitsConfig\n",
    "\n",
    "from embeddings.esmc_encoder import embed_sequences, embed_single\n",
    "from developability.biophi_api import score_sequences\n",
    "from models.mf_gp_model import MultiFidelityGP\n",
    "from models.gp_model import DevelopabilityGP\n",
    "from acquisition.acq import expected_improvement, upper_confidence_bound, thompson_sampling\n",
    "from acquisition.mutate_seq import hill_climb, genetic_algorithm, gibbs_sampling\n",
    "from utils.io import make_embedding_lookup\n",
    "\n",
    "# %% Config & constants\n",
    "from dataclasses import dataclass\n",
    "\n",
    "FID_MAP = {\"y_low\": 0.3, \"y_medium\": 0.7, \"y_high\": 0.95}\n",
    "\n",
    "@dataclass\n",
    "class PipelineConfig:\n",
    "    acq: str = \"ei\"\n",
    "    seq_opt: str = \"gs\"\n",
    "    seq_proposals: int | None = None\n",
    "    dev_weight: float = 0.3\n",
    "    xi: float = 0.01\n",
    "    kappa: float = 2.0\n",
    "    n_iter: int = 1\n",
    "    batch_k: int = 1\n",
    "    embed_components: int = 64\n",
    "    bounds_scale: float = 1.0\n",
    "\n",
    "cfg = PipelineConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d0cbdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 64 sequences\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>y_low</th>\n",
       "      <th>y_medium</th>\n",
       "      <th>y_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE...</td>\n",
       "      <td>-267.424127</td>\n",
       "      <td>-267.561455</td>\n",
       "      <td>-267.465345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE...</td>\n",
       "      <td>-267.612351</td>\n",
       "      <td>-267.202450</td>\n",
       "      <td>-267.164703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE...</td>\n",
       "      <td>-270.539386</td>\n",
       "      <td>-270.320750</td>\n",
       "      <td>-270.202944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE...</td>\n",
       "      <td>-274.479366</td>\n",
       "      <td>-274.162201</td>\n",
       "      <td>-274.071817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE...</td>\n",
       "      <td>-274.999357</td>\n",
       "      <td>-274.873697</td>\n",
       "      <td>-274.816321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence       y_low    y_medium  \\\n",
       "0  EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE... -267.424127 -267.561455   \n",
       "1  EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE... -267.612351 -267.202450   \n",
       "2  EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE... -270.539386 -270.320750   \n",
       "3  EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE... -274.479366 -274.162201   \n",
       "4  EVQLVESGGGLVQPGGSLRLSCAASGFTFKSYAMDWVRQAPGKQRE... -274.999357 -274.873697   \n",
       "\n",
       "       y_high  \n",
       "0 -267.465345  \n",
       "1 -267.164703  \n",
       "2 -270.202944  \n",
       "3 -274.071817  \n",
       "4 -274.816321  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% Load & preview raw sequences\n",
    "DATA_PATH = Path('../data/raw/cd98_64_seq.json')\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "print(f'Loaded {len(df):,} sequences')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b3aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings ready: 64 / 64 sequences\n"
     ]
    }
   ],
   "source": [
    "# %% Load or compute PCA embeddings (column: pca_embed)\n",
    "EMB_FILE = Path('../data/interim/cd98_64_embed.jsonl')\n",
    "embed_col = \"pca_embed\"\n",
    "\n",
    "# 1) Read whatever interim JSON you already have (might contain full rows)\n",
    "if EMB_FILE.exists():\n",
    "    df = pd.read_json(EMB_FILE, lines=True)\n",
    "else:\n",
    "    # start from your raw input\n",
    "    df = pd.read_json('../data/raw/cd98_64_seq.json', lines=True)\n",
    "\n",
    "# 2) If column exists, only fill NAs; else compute for all\n",
    "if embed_col in df.columns:\n",
    "    mask = df[embed_col].isna()\n",
    "else:\n",
    "    df[embed_col] = np.nan\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "\n",
    "if mask.any():\n",
    "    # train PCA on _all_ sequences once\n",
    "    full_seqs = df[['sequence']].copy()\n",
    "    df_full = embed_sequences(full_seqs, n_components=cfg.embed_components)\n",
    "    # fill missing slots\n",
    "    df.loc[mask, embed_col] = df_full.loc[mask, embed_col].values\n",
    "\n",
    "# 3) save the full DataFrame—including all original cols + pca_embed\n",
    "df.to_json(EMB_FILE, orient='records', lines=True)\n",
    "print(f\"Embeddings ready: {df[embed_col].notna().sum()} / {len(df)} sequences\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28a39331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developability scores ready: 64 / 64 sequences\n"
     ]
    }
   ],
   "source": [
    "# %% Load or compute developability scores (column: dev_score)\n",
    "DEV_FILE = Path('../data/interim/cd98_64_biophi.jsonl')\n",
    "dev_col = \"dev_score\"\n",
    "\n",
    "# 1) Load interim if present, else raw\n",
    "if DEV_FILE.exists():\n",
    "    df = pd.read_json(DEV_FILE, lines=True)\n",
    "else:\n",
    "    df = pd.read_json('../data/interim/cd98_64_embed.jsonl', lines=True)\n",
    "\n",
    "# 2) Fill or create\n",
    "if dev_col in df.columns:\n",
    "    mask = df[dev_col].isna()\n",
    "else:\n",
    "    df[dev_col] = np.nan\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "\n",
    "if mask.any():\n",
    "    scores = score_sequences(df.loc[mask, 'sequence'].tolist())\n",
    "    df.loc[mask, dev_col] = scores\n",
    "\n",
    "# 3) Save back the full DataFrame\n",
    "df.to_json(DEV_FILE, orient='records', lines=True)\n",
    "print(f\"Developability scores ready: {df[dev_col].notna().sum()} / {len(df)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d8d6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simonpritchard/miniconda3/envs/bayes_opt/lib/python3.10/site-packages/botorch/models/utils/assorted.py:270: InputDataWarning: Data (input features) is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  check_min_max_scaling(\n",
      "/Users/simonpritchard/miniconda3/envs/bayes_opt/lib/python3.10/site-packages/botorch/models/utils/assorted.py:273: InputDataWarning: Data (outcome observations) is not standardized (std = tensor([0.], dtype=torch.float64), mean = tensor([0.], dtype=torch.float64)).Please consider scaling the input to zero mean and unit variance.\n",
      "  check_standardization(Y=train_Y, raise_on_fail=raise_on_fail)\n"
     ]
    }
   ],
   "source": [
    "# %% Prepare training matrices for GP models\n",
    "# Convert embeddings from list back to array\n",
    "X = np.vstack(df[embed_col].values).astype(np.float64)\n",
    "Y = df[['y_low', 'y_medium', 'y_high']].values.astype(np.float64)\n",
    "\n",
    "F = np.hstack([[FID_MAP[c]] * len(df) for c in ['y_low', 'y_medium', 'y_high']]).astype(np.float64)\n",
    "X_rep = np.repeat(X, 3, axis=0)\n",
    "Y_flat = Y.ravel()\n",
    "\n",
    "mf_gp = MultiFidelityGP(X_rep, Y_flat, F, FID_MAP.values())\n",
    "dev_gp = DevelopabilityGP(X, df[dev_col].values.astype(np.float64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7275f8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed sequence selected (index): 54\n"
     ]
    }
   ],
   "source": [
    "# %% Select initial seed sequence\n",
    "best_idx = int(np.argmax(mf_gp.y))\n",
    "seed_seq = df.sequence.iloc[best_idx // 3]\n",
    "print('Seed sequence selected (index):', best_idx // 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "228656cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Acquisition function helper\n",
    "def make_acq(cfg, mf_gp):\n",
    "    y_best = mf_gp.y.max()\n",
    "    if cfg.acq == 'ei':\n",
    "        return lambda Xc: expected_improvement(Xc, mf_gp, y_best, cfg.xi)\n",
    "    elif cfg.acq == 'ucb':\n",
    "        return lambda Xc: upper_confidence_bound(Xc, mf_gp, cfg.kappa)\n",
    "    elif cfg.acq == 'ts':\n",
    "        return lambda Xc: thompson_sampling(Xc, mf_gp)\n",
    "    else:\n",
    "        raise ValueError(cfg.acq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b534f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our embedding‐getter\n",
    "interim_dir = Path(\"../data/interim/cd98_64_biophi.jsonl\")\n",
    "embed_col   = \"pca_embed\"\n",
    "\n",
    "get_embedding = make_embedding_lookup(\n",
    "    df,        # your DataFrame from earlier cells\n",
    "    embed_col,\n",
    "    cfg,       # your PipelineConfig instance\n",
    "    interim_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bac5f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=200_000)\n",
    "def _embed_cached(seq: str) -> np.ndarray:\n",
    "    # lazy call into your existing PCA‑backed embed_single\n",
    "    return embed_single(seq, cfg.embed_components)\n",
    "\n",
    "@lru_cache(maxsize=200_000)\n",
    "def cached_fitness(seq: str) -> float:\n",
    "    emb = _embed_cached(seq).reshape(1, -1)\n",
    "    return mf_gp.predict(emb)[0]\n",
    "\n",
    "def score_batch(seqs: list[str]) -> np.ndarray:\n",
    "    # if you ever want to evaluate many seqs at once, in one vectorized GP call:\n",
    "    embs = np.vstack([_embed_cached(s) for s in seqs])\n",
    "    return mf_gp.predict(embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2) main BO loop ---\n",
    "history = []\n",
    "assert X.shape[1] == cfg.embed_components, (\n",
    "    f\"Expected X dim {cfg.embed_components}, got {X.shape[1]}\"\n",
    ")\n",
    "print(\"asserted X\")\n",
    "\n",
    "for it in tqdm(range(cfg.n_iter), desc=\"BO iterations\"):\n",
    "    acq_fn = make_acq(cfg, mf_gp)\n",
    "    print(\"made acquisition function\")\n",
    "\n",
    "    batch_seqs, batch_embs, batch_ys = [], [], []\n",
    "    for _ in tqdm(range(cfg.batch_k), desc=f\"Iter {it:03d} candidates\", leave=True, position=1):\n",
    "        # use the *cached* fitness function\n",
    "        fitness_fn = cached_fitness\n",
    "        print(\"initialized cached fitness function\")\n",
    "\n",
    "        # 1) propose sequences\n",
    "        if cfg.seq_opt == \"hc\":\n",
    "            cand = hill_climb(\n",
    "                seed_seq,\n",
    "                fitness_fn,\n",
    "                local_k2_samples=cfg.seq_proposals or 1000,\n",
    "                restarts=1,\n",
    "            )\n",
    "            print(\"selected a candidate with hill‑climb\")\n",
    "        elif cfg.seq_opt == \"ga\":\n",
    "            cand = genetic_algorithm(\n",
    "                [seed_seq],\n",
    "                fitness_fn,\n",
    "                pop_size=cfg.seq_proposals or 200,\n",
    "            )\n",
    "        elif cfg.seq_opt == \"gs\":\n",
    "            cand = gibbs_sampling(\n",
    "                seed_seq,\n",
    "                fitness_fn,\n",
    "                iters=5, #(cfg.seq_proposals or 1000) * 10\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown seq_opt: {cfg.seq_opt}\")\n",
    "\n",
    "        # 2) dedupe & embed batch (cached)\n",
    "        cand = list(dict.fromkeys(cand))\n",
    "        print(f\"here's the candidate set (deduped): {len(cand)} seqs\")\n",
    "        embs = np.vstack([_embed_cached(s) for s in cand])\n",
    "        print(\"embedded batch with cache\")\n",
    "\n",
    "        # 3) acquisition + dev weighting\n",
    "        f_acq    = acq_fn(embs)                # vectorized\n",
    "        dev_mean = dev_gp.predict(embs)        # also vectorized\n",
    "        combined = (1 - cfg.dev_weight) * f_acq + cfg.dev_weight * dev_mean\n",
    "        idx      = int(np.argmax(combined))\n",
    "\n",
    "        # 4) pick & “experiment”\n",
    "        seq_next = cand[idx]\n",
    "        x_next   = embs[idx].astype(np.float32)\n",
    "        y_next   = -np.sum((x_next - 0.5)**2) + np.sin(5 * np.sum(x_next))\n",
    "\n",
    "        # 5) update GP & history\n",
    "        mf_gp.add_data(x_next, y_next)\n",
    "        batch_seqs.append(seq_next)\n",
    "        batch_embs.append(x_next)\n",
    "        batch_ys.append(y_next)\n",
    "        seed_seq = seq_next\n",
    "\n",
    "    history.append({\n",
    "        \"iter\":      it,\n",
    "        \"sequences\": batch_seqs,\n",
    "        \"X\":         np.vstack(batch_embs),\n",
    "        \"y\":         np.array(batch_ys),\n",
    "    })\n",
    "    print(\n",
    "        f\"Iter {it:03d} | best_y {mf_gp.y.max():.3f} | \"\n",
    "        f\"batch mean {np.mean(batch_ys):.3f}\"\n",
    "    )\n",
    "\n",
    "# %% Inspect results\n",
    "print(f\"Optimization finished. Total evaluated points: {len(mf_gp.y)}\")\n",
    "best_id = int(np.argmax(mf_gp.y))\n",
    "print(f'Best fitness: {mf_gp.y[best_id]:.3f}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayes_opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
